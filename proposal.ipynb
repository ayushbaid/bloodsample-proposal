{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__GSoC 2016 Project Proposal__\n",
    "\n",
    "__Idea 6: Mobile-based blood sample image analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Personal-Information-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Personal Information</a></div><div class=\"lev1\"><a href=\"#Background-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Background</a></div><div class=\"lev2\"><a href=\"#Education-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Education</a></div><div class=\"lev2\"><a href=\"#Relevant-Experience-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Relevant Experience</a></div><div class=\"lev1\"><a href=\"#Programming-interests-and-choice-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Programming interests and choice</a></div><div class=\"lev2\"><a href=\"#Language-skills-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Language skills</a></div><div class=\"lev2\"><a href=\"#Prior-open-source-development-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Prior open source development</a></div><div class=\"lev1\"><a href=\"#Interest-in-biology-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Interest in biology</a></div><div class=\"lev1\"><a href=\"#Project-Idea-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Project Idea</a></div><div class=\"lev2\"><a href=\"#Image-capture-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Image capture</a></div><div class=\"lev2\"><a href=\"#Preprocessing-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Preprocessing</a></div><div class=\"lev2\"><a href=\"#Detection-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Detection</a></div><div class=\"lev2\"><a href=\"#Measurement-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Measurement</a></div><div class=\"lev2\"><a href=\"#Data-collection/-Error-reporting-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Data collection/ Error reporting</a></div><div class=\"lev1\"><a href=\"#Timeline-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Timeline</a></div><div class=\"lev1\"><a href=\"#Commitments-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Commitments</a></div><div class=\"lev1\"><a href=\"#Proposal-Task-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Proposal Task</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Information #\n",
    "* Name: Ayush Baid\n",
    "* Email: ayushrakeshbaid@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "## Education\n",
    "* B.Tech and M.Tech in Electrical Engineering, Indian Institute of Technology (IIT) Bombay (2012-2017)\n",
    "\n",
    "## Relevant Experience\n",
    "Android:<br>\n",
    "* Student Intern, Sony Corporations, Tokyo: Development of automated testing framework for Android apps. (2015)\n",
    "* Winner of the Ron-Mehta Android app development contest for IIT Bombay: Developed a platform for segregation and consumption of educational videos (2013) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming interests and choice\n",
    "\n",
    "## Language skills\n",
    "Comfortable with:\n",
    "* Java (including Android)\n",
    "* MATLAB\n",
    "* Python (including scientific computing tools like numpy)\n",
    "\n",
    "Basic familiarity with:\n",
    "* C/C++\n",
    "* OpenCV\n",
    "\n",
    "\n",
    "## Prior open source development \n",
    "* Scilab Signal Processing Toolbox: Part time contributer to the development of the signal processing toolbox in Scilab which is equivalent of its MATLAB counterpart. The project is undertaken by [Free and Open Source Software for Education (FOSSEE)](http://fossee.in/) . [Github repo](https://github.com/ayushbaid/sptoolbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interest in biology #\n",
    "I am passionate about working in the field of medical image processing. I have been working on Bayesian Inference for *Joint Desmoking, Denoising, and Specularity Removal for Laparoscopy Images* ( [link](https://drive.google.com/file/d/0B-KDtD7BARvnQ1hJVUtBMm5RZFk/view?usp=sharing) )\n",
    "\n",
    "As a part of the curriculum of the Medical Image Processing course offered by my university IIT Bombay, I have studiet and implemented imaging techniques like CT and MRI and have worked with segmentation and denoising.\n",
    "\n",
    "The project idea proposed by Helikar Lab excites me due to two reasons. First, it involves image processing. Second is the implications of this project. It taps the high quality cameras which have a very high penetration in the developing countries, and provides affordable and fast tests.\n",
    "\n",
    "I would be willing to learn more about the techniques and science behind cancer biomarker dectection. This will broaden my knowledge and I will be doing my part for the community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " # Project Idea\n",
    " \n",
    "I am applying to work on the Idea-6: <b>Mobile-based blood sample image analysis</b>\n",
    " \n",
    "The complete project can be divided into 5 categories\n",
    "1. Image Capture\n",
    "2. Preprocessing\n",
    "3. Detection\n",
    "4. Measurement\n",
    "5. Data collection/Error reporting\n",
    " \n",
    "For the android app, I propose to use OpenCV for Android SDK (<a href = \"http://opencv.org/platforms/android.html\">link</a>). I propose the use of the Android SDK over C++ code as I am more comfortable with JAVA code. However, I think I will be able to gain some experience using the C++ code till the start of the GSoC coding schedule.\n",
    "\n",
    "There is also a proposed Idea 7: Web-Based Blood-Sample Image Analysis. The image processing tasks are the same for both the tasks and can be implemented in Python for rapid development and ease of debugging. After that, the code can be written for Android/web-server.\n",
    "\n",
    "For the Android app, the UI specific components are the image capture along with the display of overlay cues, display the segmented blobs to the user, and display the appropriate end results\n",
    " \n",
    "In the following sections, I suggest ideas about performing each of the 5 tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image capture\n",
    "\n",
    "The app should capture images at the highest possible resolution and avoid preprocessing which can interfere with our algorithm. However, most of the Android devices do not support raw image capture. Use of OpenCV image capture API is preffered for better integration. More research has to be done on the possibility of getting images with high resolution and low preprocessing as possible using OpenCV.\n",
    "\n",
    "<br>\n",
    "The app should have a overlay which provides cue for the grid. There are two ways to achieve this.\n",
    "\n",
    "<b>1) Static method</b><br>\n",
    "The overlay is fixed and the user has to manually adjust the phone so as to get the blobs as cued by the overlay, which will then be evaluated for correctness after the image has been captured. This method can be used only if there are only a few possible grid layout structure.\n",
    "\n",
    "* Pros: simple to implement, faster as sample layouts are packed with the app\n",
    "* Cons: flexibility in terms of data capture\n",
    "\n",
    "The implementation for this method can be done using one of the two possible approaches.\n",
    "\n",
    "1. Use of Android layout design to have two views on top of each other. One view will have the feed from the camera and the other view will have the sample overlay.\n",
    "2. Use of OpenCV APIs to create a new stream by combining the camera feed with the overlay. This method provides more control over the display of the overlays.\n",
    "\n",
    "<b>2) Dynamic method</b><br>\n",
    "The overlay is can be fixed or generated in real time, but the app keeps on checking the position of the blobs on the image with the overlay. If the blobs correspond with the overlay, then the image can be automatically captured.\n",
    "\n",
    "* Pros: user friendly\n",
    "* Cons: computationally expensive\n",
    "\n",
    "\n",
    "I consider the static method to be suitable for the project as it is less computationally expensive and we only have a few grid layouts to consider.\n",
    "\n",
    "Also, if there are multiple images to be captured for each sample, the blood sample outlines detected after one image can be used to generate a highly specific mask for the subsequent images so as to obtain a good amount of registation beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Requirements: Noise removal algorithm has to take care as to not disturb the intensities of the blood samples. There are two choices of noise removal. One is to use a bilateral filter, as we want the blood samples to be sharply demarcated and minimally affected by the background. The other choice is to do noise removal after blood blob detection and masking. Bilateral filtering will not be required as we do not have to preserve the edges.\n",
    "\n",
    "The detection algorithm uses thresholding and does not require background subtraction as such (will be explained below). If required, the corner of the captured image will be used as a background template and subtracted from the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection\n",
    "\n",
    "Assumption: For the purpose of presenting, I have considered the sample image in the last year's code. Any measure of the hue of the image can be used for detection\n",
    "\n",
    "In the task accompanying the proposal, I have used a\\* component of the <a href = \"https://en.wikipedia.org/wiki/Lab_color_space\">l\\*a\\*b colorspace</a>. This component take large positive values for red/magenta colors. Hence, it can be used to identify the regions of blood in the untreated image. It can also be used on the images captured after fluorescent quenching (included in last year's code).\n",
    "\n",
    "The a\\* component is then processed using Otsu's thresholding algorithm. The blood samples will have higher values than the paper, and hence the thresholding will generate a binary image. We can than find connected components and filter them out by their areas and location according to the overlay cue.\n",
    "\n",
    "<i>a\\* component</i>:\n",
    "![a\\* component for treated image](./a-channel-fq.png)\n",
    "\n",
    "<i>Otsu's thresholded result</i>\n",
    "![Otsu thresholding for treated image](./otsu-fq.png)\n",
    "\n",
    "\n",
    "Note that there are some regions in the thresholded image which do not correspond to blood samples. Such regions can be filtered out as they will not be present in the valid region determined by the overlay.\n",
    "\n",
    "Also, the blobs detected by thresholding are larger than they actually are, as evident in the images. Here, we can use the 1st mask obtained by Otsu's thresholding and apply Otsu's thresholding on the grayscale image to obtain a better mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement\n",
    "\n",
    "Assumption: The analysis is not performed pixel by pixel, and hence eliminating the need for registration. If registration is required, it will be performed on the thresholded image.\n",
    "\n",
    "Once the blobs are detected, the intensity can be estimated and further processing can be done to get the results. The framework developed in the task accompanying the proposal will help in this part.\n",
    "\n",
    "FRET efficiency analysis will then be performed using a suitable numerical computing library (e.g. Colt, apache commons-math )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection/ Error reporting #\n",
    "\n",
    "The user will be displayed the identified regions on which the measurements are taken, they can report it so that the algorithm can be further improved. Downsampled images and results can be a part of the data collection.\n",
    "\n",
    "In case of incorrect processing, the user has an option to report the error to the developers. We can also provide an option to manually adjust the mask and recalculate the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeline #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community Bonding Period: Follow up on the algorithms for processing. Read more about fluorescence microscopy and the science behind the biomarker detection.\n",
    "\n",
    "Each task will be implemented first in Python, for ease of debugging and rapid prototyping, and then in Java.\n",
    "\n",
    "* Week 01: May 23 - May 29\n",
    "    > - Image capture interface along with overlay cue\n",
    "* Week 02: May 30 - Jun 05\n",
    "    > - Denoising/Background removal algorithms as required\n",
    "* Week 03: Jun 06 - Jun 12\n",
    "    > - Blood samples segmentation algorithms\n",
    "* Week 04: Jun 13 - Jun 19\n",
    "    > - UI enhancements for the Android app for the functionality developed till now\n",
    "    > - Comparison of the results obtained with the ImageJ plugin\n",
    "* Week 05: Jun 20 - Jun 26\n",
    "    > - Midterm review submission\n",
    "* Week 06: Jun 27 - Jul 03\n",
    "    > - Associating the detected blobs with their position in the rectangular grid (partial)\n",
    "    > - Using the rectangular grid to get location on blobs missed by the detection algorithm\n",
    "* Week 07: Jul 04 - Jul 10\n",
    "    > - Intensity measurement from blobs\n",
    "    > - Proper UI for the functionality implemented till now\n",
    "* Week 08: Jul 11 - Jul 17\n",
    "    > - Comparison of the results obtained with the ImageJ plugin\n",
    "* Week 09: Jul 18 - Jul 24\n",
    "    > - FRET efficiency calculation\n",
    "* Week 10: Jul 25 - Jul 31\n",
    "    > - Compiling data to be reported and develop reporting mechanism\n",
    "* Week 11: Aug 01 - Aug 07\n",
    "    > - User assisted improvement of blob detection (time permitting)\n",
    "* Week 12: Aug 08 - Aug 14\n",
    "    > - Buffer week\n",
    "* Week 13 and beyond: Aug 14 - Aug 24\n",
    "    > - Buffer period, documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commitments\n",
    "\n",
    "* My classes finish on May 02, 2016. I will be having summer holidays. Classes resume from the 3rd week of July.\n",
    "* I do not have any internships or course-commitment during the summer holidays. I will be staying at my university and will be doing literature survey as a prequel to my Master's thesis. I am confident that I will be able to work on both simultaneously as I will be working over the weekend.\n",
    "* I will be available to commit 40-45 hours per week during the coding period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposal Task\n",
    "\n",
    "The proposal task has been implemented in both Python and Android. OpenCV version 3.1.0 has been used.\n",
    "\n",
    "Note: The android app does its processing in background, and thus does not hogs the UI thread.\n",
    "\n",
    "[Link](https://github.com/ayushbaid/bloodsample-proposal/blob/master/python/Assignment.html) to the html file containing the explanation, python code and results for the proposal task \n",
    "\n",
    "[Link](https://github.com/ayushbaid/bloodsample-proposal/tree/master/app-debug.apk) to the Android APK\n",
    "\n",
    "[Link](https://github.com/ayushbaid/bloodsample-proposal) to the github repo hosting both Android and Python code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_section_display": "none",
   "toc_threshold": 6,
   "toc_window_display": false
  },
  "toc_position": {
   "height": "150px",
   "left": "214.094px",
   "right": "20px",
   "top": "300px",
   "width": "600px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
